<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Parallel Computing with R</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<link rel="stylesheet"
      href="site_libs/highlight/textmate.css"
      type="text/css" />
<script src="site_libs/highlight/highlight.js"></script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GEO 503: R Spatial Data Science</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="Syllabus.html">Syllabus</a>
</li>
<li>
  <a href="Schedule.html">Schedule</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Content
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="CourseContent.html">About Course Content</a>
    </li>
    <li class="dropdown-header">Module 1: Introduction to R</li>
    <li>
      <a href="00_CourseIntroductionFrame.html">00 Course Introduction</a>
    </li>
    <li>
      <a href="01_Rintro.html">01 First Steps</a>
    </li>
    <li>
      <a href="02_DataWrangling.html">02 Data Wrangling</a>
    </li>
    <li>
      <a href="03_Plotting.html">03 Plotting</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Module 2: Spatial Analyses</li>
    <li>
      <a href="04_Spatial.html">04 Spatial Data</a>
    </li>
    <li>
      <a href="05_Raster.html">05 Spatial Raster Data</a>
    </li>
    <li>
      <a href="06_RasterTwo.html">06 More Raster Data</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Module 2: Advanced Programming</li>
    <li>
      <a href="07_Reproducibile.html">07 Reproducible Research</a>
    </li>
    <li>
      <a href="08_WeatherData.html">08 Weather Data Processing</a>
    </li>
    <li class="divider"></li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Assignments
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="Homework.html">Homeworks</a>
    </li>
    <li>
      <a href="PackageIntro.html">Package Introduction</a>
    </li>
    <li>
      <a href="Project.html">Final Project</a>
    </li>
  </ul>
</li>
<li>
  <a href="Resources.html">Resources</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/adammwilson/RDataScience">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Parallel Computing with R</h1>

</div>


<pre class="r"><code>library(knitr)
library(raster)
library(rasterVis)
library(dplyr)
library(ggplot2)

## New Packages
library(foreach)
library(doParallel)
library(arm)
library(coda)
library(ggmcmc)
library(fields)
library(snow)</code></pre>
<p>If you don’t have the packages above, install them in the package manager or by running <code>install.packages(&quot;doParallel&quot;)</code>.</p>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<div id="serial-computing" class="section level2">
<h2>Serial Computing</h2>
<p>Most (legacy) software is written for serial computation:</p>
<ul>
<li>Problem broken into discrete set of instructions</li>
<li>Instructions executed sequentially on a single processor</li>
</ul>
<p><img src="assets/serialProblem.gif" alt="https://computing.llnl.gov/tutorials/parallel_comp/" /> <span style="color:grey; font-size:1em;">Figure from <a href="https://computing.llnl.gov/tutorials/parallel_comp/">here</a> </span></p>
</div>
<div id="parallel-computation" class="section level2">
<h2>Parallel computation</h2>
<p>Parallel computing is the simultaneous use of multiple compute resources:</p>
<ul>
<li>Problem divided into discrete parts that can be solved concurrently</li>
<li>Instructions from each part execute simultaneously on different processors</li>
<li>An overall control/coordination mechanism is employed</li>
</ul>
<p><img src="assets/parallelProblem.gif" alt="https://computing.llnl.gov/tutorials/parallel_comp/" /> <span style="color:grey; font-size:1em;">Figure from <a href="https://computing.llnl.gov/tutorials/parallel_comp/">here</a> </span></p>
</div>
<div id="flynns-taxonomy" class="section level2">
<h2>Flynn’s taxonomy</h2>
<p>A classification of computer architectures (<a href="http://dx.doi.org/10.1109/TC.1972.5009071">Flynn, 1972</a>)</p>
<ul>
<li><em>Single Instruction, Single Data (SISD)</em>
<ul>
<li>No parallelization</li>
</ul></li>
<li><em>Single Instruction, Multiple Data (SIMD)</em>
<ul>
<li>Run the same code/analysis on different datasets</li>
<li>Examples:
<ul>
<li>different species in species distribution model</li>
<li>same species under different climates</li>
<li>different MCMC chains from a Bayesian Model</li>
</ul></li>
</ul></li>
<li><em>Multiple Instruction, Single Data (MISD)</em>
<ul>
<li>Run different code/analyses on the same data</li>
<li>Examples:
<ul>
<li>One species, multiple models</li>
</ul></li>
</ul></li>
<li><em>Multiple Instruction, Multiple Data streams (MIMD)</em>
<ul>
<li>Run different code/analyses on different data</li>
<li>Examples:
<ul>
<li>Different species &amp; different models</li>
</ul></li>
</ul></li>
</ul>
<p><img src="assets/SISD.png" alt="http://en.wikipedia.org/wiki/Flynn%27s_taxonomy" /> <span style="color:grey; font-size:1em;">Figure from <a href="http://en.wikipedia.org/wiki/Flynn%27s_taxonomy">here</a></span></p>
</div>
<div id="our-focus-single-instruction-multiple-data-simd" class="section level2">
<h2>Our focus: <em>Single Instruction, Multiple Data (SIMD)</em></h2>
<ol style="list-style-type: decimal">
<li>Parallel functions within an R script
<ul>
<li>starts on single processor</li>
<li>runs looped elements on multiple ‘slave’ processors</li>
<li>returns results of all iterations to the original instance</li>
<li>foreach, multicore, plyr, raster</li>
</ul></li>
<li>Alternative: run many separate instances of R in parallel with <code>Rscript</code>
<ul>
<li>need another operation to combine the results</li>
<li>preferable for long, complex jobs</li>
<li>NOT planning to discuss in this session</li>
</ul></li>
</ol>
<div id="r-packages" class="section level3">
<h3>R Packages</h3>
<p>There are many R packages for parallelization, check out the CRAN Task View on <a href="http://cran.r-project.org/web/views/HighPerformanceComputing.html">High-Performance and Parallel Computing</a> for an overview. For example:</p>
<ul>
<li><a href="http://cran.r-project.org/web/packages/Rmpi/index.html">Rmpi</a>: Built on MPI (Message Passing Interface), a de facto standard in parallel computing.</li>
<li><a href="http://cran.r-project.org/web/packages/snow/index.html">snow</a>: Simple Network of Workstations can use several standards (PVM, MPI, NWS)</li>
<li><a href="https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf">parallel</a> Built in R package (since v2.14.0).</li>
</ul>
<hr />
</div>
</div>
<div id="foreach-package" class="section level2">
<h2>Foreach Package</h2>
<p>In this session we’ll focus on the foreach package, which has numerous advantages including:</p>
<ul>
<li>intuitive <code>for()</code> loop-like syntax</li>
<li>flexibility of choosing a parallel ‘backend’ for laptops through to supercomputers (using multicore, parallel, snow, Rmpi, etc.)</li>
<li>nice options for combining output from parallelized jobs</li>
</ul>
<div id="documentation-for-foreach" class="section level3">
<h3>Documentation for foreach:</h3>
<ul>
<li><a href="http://cran.r-project.org/web/packages/foreach/foreach.pdf">foreach manual</a></li>
<li><a href="http://cran.r-project.org/web/packages/foreach/vignettes/foreach.pdf">foreach vignette</a></li>
<li><a href="http://cran.r-project.org/web/packages/foreach/vignettes/nested.pdf">Nested Loops</a></li>
</ul>
</div>
<div id="foreach-backends" class="section level3">
<h3>Foreach <em>backends</em></h3>
<ul>
<li><a href="http://cran.r-project.org/web/packages/doParallel/index.html">doParallel</a> best for use on multicore machines (uses <code>fork</code> on linux/mac and <code>snow</code> on windows).</li>
<li><a href="http://cran.r-project.org/web/packages/doMPI/vignettes/doMPI.pdf">doMPI</a>: Interface to MPI (Message-Passing Interface)</li>
<li><a href="http://cran.r-project.org/web/packages/doSNOW/doSNOW.pdf">doSNOW</a>: Simple Network of Workstations</li>
</ul>
</div>
</div>
</div>
<div id="simple-examples" class="section level1">
<h1>Simple examples</h1>
<div id="sequential-for-loop" class="section level2">
<h2><em>Sequential</em> <code>for()</code> loop</h2>
<pre class="r"><code>x=vector()
for(i in 1:3) x[i]=i^2
x</code></pre>
</div>
<div id="sequential-foreach-loop" class="section level2">
<h2><em>Sequential</em> <code>foreach()</code> loop</h2>
<pre class="r"><code>x &lt;- foreach(i=1:3) %do% i^2
x</code></pre>
<p>Note that <code>x</code> is a list with one element for each iterator variable (<code>i</code>). You can also specify a function to use to combine the outputs with <code>.combine</code>. Let’s concatenate the results into a vector with <code>c</code>.</p>
</div>
<div id="sequential-foreach-loop-with-.combine" class="section level2">
<h2><em>Sequential</em> <code>foreach()</code> loop with <code>.combine</code></h2>
<pre class="r"><code>x &lt;- foreach(i=1:3,.combine=&#39;c&#39;) %do% i^2
x</code></pre>
<p>Tells <code>foreach()</code> to first calculate each iteration, then <code>.combine</code> them with a <code>c(...)</code></p>
</div>
<div id="sequential-foreach-loop-with-.combine-1" class="section level2">
<h2><em>Sequential</em> <code>foreach()</code> loop with <code>.combine</code></h2>
<pre class="r"><code>x &lt;- foreach(i=1:3,.combine=&#39;rbind&#39;) %do% i^2
x</code></pre>
</div>
<div id="your-turn" class="section level2">
<h2>Your Turn</h2>
<p>Write a <code>foreach()</code> loop that:</p>
<ul>
<li>generates 10 sets of 100 random values from a normal distribution (<code>rnorm()</code>)</li>
<li>column-binds (<code>cbind</code>) them.</li>
</ul>
<p><br><br><br><br><br><br><br><br><br><br><br><br><br><br></p>
<pre class="r"><code>x &lt;- foreach(i=1:10,.combine=&#39;cbind&#39;) %do% rnorm(100)
head(x)%&gt;%kable()
dim(x)</code></pre>
</div>
<div id="parallel-foreach-loop" class="section level2">
<h2><em>Parallel</em> <code>foreach()</code> loop</h2>
<p>So far we’ve only used <code>%do%</code> which only uses a single processor.</p>
<p>Before running <code>foreach()</code> in parallel, you have to register a <em>parallel backend</em> with one of the <code>do</code> functions such as <code>doParallel()</code>. On most multicore systems, the easiest backend is typically <code>doParallel()</code>. On linux and mac, it uses <code>fork</code> system call and on Windows machines it uses <code>snow</code> backend. The nice thing is it chooses automatically for the system.</p>
<pre class="r"><code># register specified number of workers
registerDoParallel(3)
# or, reserve all all available cores 
#registerDoParallel()       
# check how many cores (workers) are registered
getDoParWorkers()   </code></pre>
<blockquote>
<p><em>NOTE</em> It may be a good idea to use n-1 cores for processing (so you can still use your computer to do other things while the analysis is running)</p>
</blockquote>
<p>To run in parallel, simply change the <code>%do%</code> to <code>%dopar%</code>. Wasn’t that easy?</p>
<pre class="r"><code>## run the loop
x &lt;- foreach(i=1:3, .combine=&#39;c&#39;) %dopar% i^2
x</code></pre>
</div>
<div id="a-slightly-more-complicated-example" class="section level2">
<h2>A slightly more complicated example</h2>
<p>In this section we will:</p>
<ol style="list-style-type: decimal">
<li>Generate data with known parameters</li>
<li>Fit a set of regression models using subsets of the complete dataset (e.g. bootstrapping)</li>
<li>Compare processing times for sequential vs. parallel execution</li>
</ol>
<p>For more on motivations to bootstrap, see <a href="http://www.sagepub.com/sites/default/files/upm-binaries/21122_Chapter_21.pdf">here</a>.</p>
<p>Make up some data:</p>
<pre class="r"><code>n &lt;- 100000              # number of data points
x1 &lt;- rnorm (n)          # make up x1 covariate
b0 &lt;- 1.8                # set intercept (beta0)
b1 &lt;- -1.5                # set beta1
p = invlogit(b0+b1*x1)
y &lt;- rbinom (n, 1, p)  # simulate data with noise
data=cbind.data.frame(y=y,x1=x1,p=p)</code></pre>
<p>Let’s look at the data:</p>
<pre class="r"><code>kable(head(data),row.names = F,digits = 2)</code></pre>
<pre class="r"><code>ggplot(data,aes(y=x1,x=as.factor(y)))+
  geom_boxplot()+
  coord_flip()+
  geom_line(aes(x=p+1,y=x1),col=&quot;red&quot;,size=2,alpha=.5)+
  xlab(&quot;Binary Response&quot;)+
  ylab(&quot;Covariate&quot;)</code></pre>
<div id="sampling-from-a-dataset-with-sample_n" class="section level3">
<h3>Sampling from a dataset with <code>sample_n()</code></h3>
<pre class="r"><code>size=5
sample_n(data,size,replace=T)</code></pre>
</div>
<div id="simple-generalized-linear-model" class="section level3">
<h3>Simple Generalized Linear Model</h3>
<p>This is the formal definition of the model we’ll use:</p>
<p><span class="math inline"><em>y</em><sub><em>i</em></sub> ∼ <em>B</em><em>e</em><em>r</em><em>n</em><em>o</em><em>u</em><em>l</em><em>l</em><em>i</em>(<em>p</em><sub><em>i</em></sub>)</span></p>
<p><span class="math inline"><em>l</em><em>o</em><em>g</em><em>i</em><em>t</em>(<em>p</em><sub><em>i</em></sub>)=<em>β</em><sub>0</sub> + <em>β</em><sub>1</sub><em>X</em><sub><em>i</em></sub></span></p>
<p>The index <span class="math inline"><em>i</em></span> identifies each grid cell (data point). <span class="math inline"><em>β</em><sub>0</sub></span> - <span class="math inline"><em>β</em><sub>1</sub></span> are model coefficients (intercept and slope), and <span class="math inline"><em>y</em><sub><em>i</em></sub></span> is the simulated observation from cell <span class="math inline"><em>i</em></span>.</p>
<pre class="r"><code>trials = 10000
tsize = 100</code></pre>
<pre class="r"><code>  ptime &lt;- system.time({
  result &lt;- foreach(i=1:trials,
                    .combine = rbind.data.frame) %dopar% {
  tdata=sample_n(data,tsize,replace=TRUE)
  M1=glm(y ~ x1, data=tdata, family=binomial(link=&quot;logit&quot;))
  ## return parameter estimates
  cbind.data.frame(trial=i,t(coefficients(M1)))
    }
  })
ptime</code></pre>
<p>Look at <code>results</code> object containing slope and aspect from subsampled models. There is one row per sample with columns for the estimated intercept and slope for that sample.</p>
<pre class="r"><code>kable(head(result),digits = 2)</code></pre>
<pre class="r"><code>ggplot(dplyr::select(result,everything(),Intercept=contains(&quot;Intercept&quot;)))+
  geom_density(aes(x=Intercept),fill=&quot;black&quot;,alpha=.2)+
  geom_vline(aes(xintercept=b0),size=2)+
  geom_density(aes(x=x1),fill=&quot;red&quot;,alpha=.2)+
  geom_vline(aes(xintercept=b1),col=&quot;red&quot;,size=2)+
  xlim(c(-5,5))+
  ylab(&quot;Parameter Value&quot;)+
  xlab(&quot;Density&quot;)</code></pre>
<p>So we were able to perform 10^{4} separate model fits in seconds. Let’s see how long it would have taken in sequence.</p>
<pre class="r"><code>  stime &lt;- system.time({
  result &lt;- foreach(i=1:trials,
                    .combine = rbind.data.frame) %do% {
  tdata=sample_n(data,tsize,replace=TRUE)
  M1=glm(y ~ x1, data=tdata,family=binomial(link=&quot;logit&quot;))
  ## return parameter estimates
  cbind.data.frame(trial=i,t(coefficients(M1)))
    }
  })
stime</code></pre>
<p>So we were able to run 10^{4} separate model fits in seconds when using 1 CPUs and seconds on one CPU. That’s X faster for this simple example.</p>
</div>
</div>
<div id="your-turn-1" class="section level2">
<h2>Your Turn</h2>
<ul>
<li>Generate some random as follows:</li>
</ul>
<pre class="r"><code>n &lt;- 10000              # number of data points
x1 &lt;- rnorm (n)          # make up x1 covariate
b0 &lt;- 25                # set intercept (beta0)
b1 &lt;- -15                # set beta1
y &lt;- rnorm (n, b0+b1*x1,10)  # simulate data with noise
data2=cbind.data.frame(y=y,x1=x1)</code></pre>
<p>Write a parallel <code>foreach()</code> loop that:</p>
<ul>
<li>selects a sample (as above) with <code>sample_n()</code></li>
<li>fits a ‘normal’ linear model with <code>lm()</code></li>
<li>Compiles the coefficient of determination (R^2) from each model</li>
</ul>
<p>Hint: see <code>?summary.lm</code>.</p>
<p><br><br><br><br><br><br><br><br><br><br><br><br><br></p>
<pre class="r"><code>trials = 100
tsize = 100

  result &lt;- foreach(i=1:trials,.combine = rbind.data.frame) %dopar% {
  tdata=sample_n(data2,tsize,replace=TRUE)
  M1=lm(y ~ x1, data=tdata)
  cbind.data.frame(trial=i,
                   t(coefficients(M1)),
                   r2=summary(M1)$r.squared,
                   aic=AIC(M1))
  }


ggplot(data2,aes(y=y,x=x1))+
  geom_point(col=&quot;grey&quot;)+
  geom_abline(data=dplyr::select(result,everything(),Intercept=contains(&quot;Intercept&quot;)),
              aes(intercept=Intercept,slope=x1),alpha=.5)</code></pre>
<div id="writing-data-to-disk" class="section level3">
<h3>Writing data to disk</h3>
<p>For long-running processes, you may want to consider writing results to disk <em>as-you-go</em> rather than waiting until the end in case of a problem (power failure, single job failure, etc.).</p>
<pre class="r"><code>## assign target directory
td=tempdir()

  foreach(i=1:trials,
                    .combine = rbind.data.frame) %dopar% {
  tdata=sample_n(data,tsize,replace=TRUE)
  M1=glm(y ~ x1, data=tdata, family=binomial(link=&quot;logit&quot;))
  ## return parameter estimates
  results=cbind.data.frame(trial=i,t(coefficients(M1)))
  
  ## write results to disk
  file=paste0(td,&quot;/results_&quot;,i,&quot;.csv&quot;)
  write.csv(results,file=file)
  return(NULL)
    }</code></pre>
<p>That will save the result of each subprocess to disk (be careful about duplicated file names!):</p>
<pre class="r"><code>list.files(td,pattern=&quot;results&quot;)%&gt;%head()</code></pre>
</div>
<div id="other-useful-foreach-parameters" class="section level3">
<h3>Other useful <code>foreach</code> parameters</h3>
<ul>
<li><code>.inorder</code> (true/false) results combined in the same order that they were submitted?</li>
<li><code>.errorhandling</code> (stop/remove/pass)</li>
<li><code>.packages</code> packages to made available to sub-processes</li>
<li><code>.export</code> variables to export to sub-processes</li>
</ul>
</div>
</div>
</div>
<div id="spatial-example" class="section level1">
<h1>Spatial example</h1>
<p>In this section we will:</p>
<ol style="list-style-type: decimal">
<li>Generate some <em>spatial</em> data</li>
<li>Tile the region to facilitate processing the data in parallel.</li>
<li>Perform a moving window mean for the full area</li>
<li>Compare processing times for sequential vs. parallel execution</li>
</ol>
<div id="generate-spatial-data" class="section level2">
<h2>Generate Spatial Data</h2>
<p>A function to generate <code>raster</code> object with spatial autocorrelation.</p>
<pre class="r"><code>simrast=function(nx=60,ny=60,theta=10,seed=1234){
      ## create a random raster with some spatial structure
      ## Theta is the scale of an exponential decay function.  
      ## This controls degree of autocorrelation, 
      ## values close to 1 are close to random while values near nx/4 have high autocorrelation
     r=raster(nrows=ny, ncols=nx,vals=1,xmn=-nx/2, xmx=nx/2, ymn=-ny/2, ymx=ny/2)
      names(r)=&quot;z&quot;
      # Simulate a Gaussian random field with an exponential covariance function
      set.seed(seed)  #set a seed so everyone&#39;s maps are the same
      grid=list(x=seq(xmin(r),xmax(r)-1,by=res(r)[1]),y=seq(ymin(r),ymax(r)-1,res(r)[2]))
      obj&lt;-Exp.image.cov(grid=grid, theta=theta, setup=TRUE)
      look&lt;- sim.rf( obj)      
      values(r)=t(look)*10
      return(r)
      }</code></pre>
<p>Generate a raster using <code>simrast</code>.</p>
<pre class="r"><code>r=simrast(nx=3000,ny=1000,theta = 100)
r</code></pre>
<p>Plot the raster showing the grid.</p>
<pre class="r"><code>gplot(r)+
  geom_raster(aes(fill = value))+ 
  scale_fill_gradient(low = &#39;white&#39;, high = &#39;blue&#39;)+
  coord_equal()+ylab(&quot;Y&quot;)+xlab(&quot;X&quot;)</code></pre>
</div>
<div id="tile-the-region" class="section level2">
<h2>“Tile” the region</h2>
<p>To parallelize spatial data, you often need to <em>tile</em> the data and process each tile separately. Here is a function that will take a bounding box, tile size and generate a tiling system. If given an <code>overlap</code> term, it will also add buffers to the tiles to reduce/eliminate edge effects, though this depends on what algorithm/model you are using.</p>
<pre class="r"><code>tilebuilder=function(raster,size=10,overlap=NULL){
  ## get raster extents
  xmin=xmin(raster)
  xmax=xmax(raster)
  ymin=ymin(raster)
  ymax=ymax(raster)
  xmins=c(seq(xmin,xmax-size,by=size))
  ymins=c(seq(ymin,ymax-size,by=size))
  exts=expand.grid(xmin=xmins,ymin=ymins)
  exts$ymax=exts$ymin+size
  exts$xmax=exts$xmin+size
  if(!is.null(overlap)){
  #if overlapped tiles are requested, create new columns with buffered extents
    exts$yminb=exts$ymin
    exts$xminb=exts$xmin
    exts$ymaxb=exts$ymax
    exts$xmaxb=exts$xmax
    
    t1=(exts$ymin-overlap)&gt;=ymin
    exts$yminb[t1]=exts$ymin[t1]-overlap
    t2=exts$xmin-overlap&gt;=xmin
    exts$xminb[t2]=exts$xmin[t2]-overlap    
    t3=exts$ymax+overlap&lt;=ymax
    exts$ymaxb[t3]=exts$ymax[t3]+overlap
    t4=exts$xmax+overlap&lt;=xmax
    exts$xmaxb[t4]=exts$xmax[t4]+overlap  
  }
  exts$tile=1:nrow(exts)
  return(exts)
}</code></pre>
<p>Generate a tiling system for that raster. Here will use only three tiles (feel free to play with this).</p>
<pre class="r"><code>jobs=tilebuilder(r,size=1000,overlap=80)
kable(jobs,row.names = F,digits = 2)</code></pre>
<p>Plot the raster showing the grid.</p>
<pre class="r"><code>ggplot(jobs)+
  geom_raster(aes(x=coordinates(r)[,1],y=coordinates(r)[,2],fill = values(r)))+ 
  scale_fill_gradient(low = &#39;white&#39;, high = &#39;blue&#39;)+
  geom_rect(mapping=aes(xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax),
            fill=&quot;transparent&quot;,lty=&quot;dashed&quot;,col=&quot;darkgreen&quot;)+
  geom_rect(aes(xmin=xminb,xmax=xmaxb,ymin=yminb,ymax=ymaxb),
            fill=&quot;transparent&quot;,col=&quot;black&quot;)+
  geom_text(aes(x=(xminb+xmax)/2,y=(yminb+ymax)/2,label=tile),size=10)+
  coord_equal()+ylab(&quot;Y&quot;)+xlab(&quot;X&quot;)</code></pre>
</div>
<div id="run-a-simple-spatial-analysis-focal-moving-window" class="section level2">
<h2>Run a simple spatial analysis: <code>focal</code> moving window</h2>
<p>Use the <code>focal</code> function from the raster package to calculate a 3x3 moving window mean over the raster.</p>
<pre class="r"><code>stime2=system.time({
  r_focal1=focal(r,w=matrix(1,101,101),mean,pad=T)
  })
stime2

## plot it
gplot(r_focal1)+
  geom_raster(aes(fill = value))+ 
  scale_fill_gradient(low = &#39;white&#39;, high = &#39;blue&#39;)+
  coord_equal()+ylab(&quot;Y&quot;)+xlab(&quot;X&quot;)</code></pre>
<p>That works great (and pretty fast) for this little example, but as the data (or the size of the window) get larger, it can become prohibitive.</p>
</div>
<div id="repeat-the-analysis-but-parallelize-using-the-tile-system." class="section level2">
<h2>Repeat the analysis, but parallelize using the tile system.</h2>
<p>First write a function that breaks up the original raster, computes the focal mean, then puts it back together. You could also put this directly in the <code>foreach()</code> loop.</p>
<pre class="r"><code>focal_par=function(i,raster,jobs,w=matrix(1,101,101)){
  ## identify which row in jobs to process
  t_ext=jobs[i,]
  ## crop original raster to (buffered) tile
  r2=crop(raster,extent(t_ext$xminb,t_ext$xmaxb,t_ext$yminb,t_ext$ymaxb))
  ## run moving window mean over tile
  rf=focal(r2,w=w,mean,pad=T)
  ## crop to tile
  rf2=crop(rf,extent(t_ext$xmin,t_ext$xmax,t_ext$ymin,t_ext$ymax))
  ## return the object - could also write the file to disk and aggregate later outside of foreach()
  return(rf2)
}</code></pre>
<p>Run the parallelized version.</p>
<pre class="r"><code>registerDoParallel(3)   

ptime2=system.time({
  r_focal=foreach(i=1:nrow(jobs),.combine=merge,.packages=c(&quot;raster&quot;)) %dopar% focal_par(i,r,jobs)
  })</code></pre>
<p>Are the outputs the same?</p>
<pre class="r"><code>identical(r_focal,r_focal1)</code></pre>
<p>So we were able to process the data in seconds when using 1 CPUs and seconds on one CPU. That’s X faster for this simple example.</p>
</div>
<div id="parallelized-raster-functions" class="section level2">
<h2>Parallelized Raster functions</h2>
<p>Some functions in raster package also easy to parallelize.</p>
<pre class="r"><code>ncores=2
beginCluster(ncores)

fn=function(x) x^3

system.time(fn(r))
system.time(clusterR(r, fn, verbose=T))

endCluster()</code></pre>
<p>Does <em>not</em> work with:</p>
<ul>
<li>merge</li>
<li>crop</li>
<li>mosaic</li>
<li>(dis)aggregate</li>
<li>resample</li>
<li>projectRaster</li>
<li>focal</li>
<li>distance</li>
<li>buffer</li>
<li>direction</li>
</ul>
</div>
</div>
<div id="high-performance-computers-hpc" class="section level1">
<h1>High Performance Computers (HPC)</h1>
<p><em>aka</em> <em>supercomputers</em>, for example, check out the <a href="https://www.buffalo.edu/ccr.html">University at Buffalo HPC</a></p>
<div class="figure">
<img src="assets/CCR.png" />

</div>
<p>Working on a cluster can be quite different from a laptop/workstation. The most important difference is the existence of <em>scheduler</em> that manages large numbers of individual tasks.</p>
<div id="slurm-and-r" class="section level2">
<h2>SLURM and R</h2>
<p>You typically don’t run the script <em>interactively</em>, so you need to edit your script to ‘behave’ like a normal <code>#!</code> (linux command line) script. This is easy with <a href="http://cran.r-project.org/web/packages/getopt/index.html">getopt</a> package.</p>
<pre class="r"><code>cat(paste(&quot;
          library(getopt)
          ## get options
          opta &lt;- getopt(
              matrix(c(
                  &#39;date&#39;, &#39;d&#39;, 1, &#39;character&#39;
              ), ncol=4, byrow=TRUE))
          ## extract value
          date=as.Date(opta$date) 
          
          ## Now your script using date as an input
          print(date+1)
          q(\&quot;no\&quot;)
          &quot;
          ),file=paste(&quot;script.R&quot;,sep=&quot;&quot;))</code></pre>
<p>Then you can run this script from the command line like this:</p>
<pre class="r"><code>Rscript script.R --date 2013-11-05</code></pre>
<p>You will need the complete path if <code>Rscript</code> is not on your system path. For example, on OS X, it might be at <code>/Library/Frameworks/R.framework/Versions/3.2/Resources/Rscript</code>.</p>
<p>Or even from within R like this:</p>
<pre class="r"><code>system(&quot;Rscript script.R --date 2013-11-05&quot;,intern=T)</code></pre>
<div id="driving-cluster-from-r" class="section level3">
<h3>Driving cluster from R</h3>
<p>Possible to drive the cluster from within R via SLURM. First, define the jobs and write that file to disk:</p>
<pre class="r"><code>script=&quot;script.R&quot;
dates=seq(as.Date(&quot;2000-01-01&quot;),as.Date(&quot;2000-12-31&quot;),by=60)
pjobs=data.frame(jobs=paste(script,&quot;--date&quot;,dates))

write.table(pjobs,                     
  file=&quot;process.txt&quot;,
  row.names=F,col.names=F,quote=F)</code></pre>
<p>This table has one row per task:</p>
<pre class="r"><code>pjobs</code></pre>
<p>Now identify other parameters for SLURM.</p>
<pre class="r"><code>### Set up submission script
nodes=2
walltime=5</code></pre>
</div>
<div id="write-the-slurm-script" class="section level3">
<h3>Write the SLURM script</h3>
<p><a href="https://www.buffalo.edu/ccr.html">More information here</a></p>
<pre class="r"><code>### write SLURM script to disk from R

cat(paste(&quot;#!/bin/sh
#SBATCH --partition=general-compute
#SBATCH --time=00:&quot;,walltime,&quot;:00
#SBATCH --nodes=&quot;,nodes,&quot;
#SBATCH --ntasks-per-node=8
#SBATCH --constraint=IB
#SBATCH --mem=300
# Memory per node specification is in MB. It is optional. 
# The default limit is 3000MB per core.
#SBATCH --job-name=\&quot;date_test\&quot;
#SBATCH --output=date_test-srun.out
#SBATCH --mail-user=adamw@buffalo.edu
#SBATCH --mail-type=ALL
##SBATCH --requeue
#Specifies that the job will be requeued after a node failure.
#The default is that the job will not be requeued.

## Load necessary modules
module load openmpi/gcc-4.8.3/1.8.4   
module load R

IDIR=~
WORKLIST=$IDIR/process.txt
EXE=Rscript
LOGSTDOUT=$IDIR/log/stdout
LOGSTDERR=$IDIR/log/stderr
          
### use mpiexec to parallelize across lines in process.txt
mpiexec -np $CORES xargs -a $WORKLIST -p $EXE 1&gt; $LOGSTDOUT 2&gt; $LOGSTDERR
&quot;,sep=&quot;&quot;),file=paste(&quot;slurm_script.txt&quot;,sep=&quot;&quot;))</code></pre>
<p>Now we have a list of jobs and a qsub script that points at those jobs with the necessary PBS settings.</p>
<pre class="r"><code>## run it!
system(&quot;sbatch slurm_script.txt&quot;)
## Check status with squeue
system(&quot;squeue -u adamw&quot;)</code></pre>
<p>For more detailed information about the UB HPC, <a href="https://www.buffalo.edu/ccr/support/UserGuide.html">see the CCR Userguide</a>.</p>
</div>
</div>
</div>
<div id="summary" class="section level1">
<h1>Summary</h1>
<blockquote>
<p>Each task should involve computationally-intensive work. If the tasks are very small, it can take <em>longer</em> to run in parallel.</p>
</blockquote>
<div id="choose-your-method" class="section level2">
<h2>Choose your method</h2>
<ol style="list-style-type: decimal">
<li>Run from master process (e.g. <code>foreach</code>)
<ul>
<li>easier to implement and collect results</li>
<li>fragile (one failure can kill it and lose results)</li>
<li>clumsy for <em>big</em> jobs</li>
</ul></li>
<li>Run as separate R processes
<ul>
<li>see <a href="http://cran.r-project.org/web/packages/getopt/index.html"><code>getopt</code></a> library</li>
<li>safer for big jobs: each job completely independent</li>
<li>update job list to re-run incomplete submissions</li>
<li>compatible with slurm / cluster computing</li>
<li>forces you to have a clean processing script</li>
</ul></li>
</ol>
</div>
<div id="further-reading" class="section level2">
<h2>Further Reading</h2>
<ul>
<li><a href="http://cran.r-project.org/web/views/HighPerformanceComputing.html">CRAN Task View: High-Performance and Parallel Computing with R</a></li>
<li><a href="www.stat.uiowa.edu/~luke/talks/uiowa03.pdf">Simple Parallel Statistical Computing in R</a></li>
<li><a href="http://download.springer.com/static/pdf/832/chp%253A10.1007%252F978-3-642-13872-0_64.pdf?auth66=1415215123_43bf0cbf5ae8f5143b7ee309ff5e3556&amp;ext=.pdf">Parallel Computing with the R Language in a Supercomputing Environment</a></li>
</ul>
</div>
</div>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-2684666-2', 'auto');
  ga('send', 'pageview');
</script>

<!-- disqus -->
<div id="disqus_thread" style="margin-top: 45px;"></div>
<script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rdataanalysis'; // required: replace example with your forum shortname
        var disqus_identifier = "{{ page.url }}";
        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq         );
        })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">
              comments powered by Disqus.</a>
</noscript>


<!-- give the footer some space -->
<br/>
<br/>

<footer id="site-footer">
  <div id="footer1">
  <a href="http://www.adamwilson.us"><img src="img/wilson.png" alt="logo" width=40px></a>
  <a href="http://adamwilson.us/#contact"><i class="fa fa-envelope fa-2x"></i></a> 
  <a href="https://twitter.com/AdamWilsonLab"><i class="fa fa-twitter fa-2x"></i></a> 
  <a href="https://github.com/AdamMWilson"><i class="fa fa-github fa-2x"></i></a>
  </div>
  <div id="footer2">
  <a rel="license" property="http://creativecommons.org/ns#license"
  href="http://creativecommons.org/licenses/by/4.0/" ><img src="img/cc-by.svg" alt="cc-by"/></a> 
  </div>
</footer>



</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});


</script>


</body>
</html>
